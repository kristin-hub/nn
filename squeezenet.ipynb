!pip install git+https://github.com/rcmalli/keras-squeezenet.git
!pip install keras_squeezenet



from google.colab import drive
drive.mount('/content/drive')



from os import listdir, rename
from os.path import isfile, join

source_dir = 'drive/My Drive/data'
train_dir = 'drive/My Drive/data/train'
validation_dir = 'drive/My Drive/data/validation'
test_dir = 'drive/My Drive/data/test'

fake_dir = 'fake'
orig_dir = 'orig'

images = [f for f in listdir(source_dir) if isfile(join(source_dir, f))]



import numpy as np
import tensorflow as tf

from keras.backend.tensorflow_backend import set_session

np.random.seed(0)
tf.set_random_seed(0)

config = tf.ConfigProto()
config.gpu_options.allow_growth = True
set_session(tf.Session(config=config))



train_data_dir = 'drive/My Drive/data/train'
test_data_dir = 'drive/My Drive/data/test'
validation_data_dir = 'drive/My Drive/data/validation'

img_height = 224
img_width = 224

batch_size = 16
epochs = 150

train_first_class = 4112
train_second_class = 4112

val_first_class = 1120
val_second_class = 1120

nb_train_samples = train_first_class + train_second_class
nb_validation_samples = val_first_class + val_second_class



Прогоняем наш датасет через сверточные слои предобученной сети, чтобы получить признаки и сохраняем их
from keras.layers import Input

from keras_squeezenet import SqueezeNet
from keras.applications.imagenet_utils import preprocess_input, decode_predictions
from keras.preprocessing import image

input_tensor = Input(shape=(img_height,img_width,3))

base_model = SqueezeNet(weights='imagenet',
                          include_top=False,
                          input_shape=(img_width, img_height, 3),
                          pooling='avg')

data_generator = image.ImageDataGenerator(rescale=1. / 255)

train_generator = data_generator.flow_from_directory(
    train_data_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode=None,
    shuffle=False)

bottleneck_features_train = base_model.predict_generator(
        train_generator, 
        nb_train_samples // batch_size)

print('Prediction of the training set finished.')

np.save(open('bottleneck_features_train.npy', 'wb'),
            bottleneck_features_train)

validation_generator = data_generator.flow_from_directory(
    validation_data_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode=None,
    shuffle=False)

bottleneck_features_validation = base_model.predict_generator(
        validation_generator, 
        nb_validation_samples // batch_size)

print('Prediction of the validation set finished.')

np.save(open('bottleneck_features_validation.npy', 'wb'),
            bottleneck_features_validation)
            
            

train_data = np.load(open('bottleneck_features_train.npy', 'rb'))
train_labels = np.array([0] * train_first_class + [1] * train_second_class)

validation_data = np.load(open('bottleneck_features_validation.npy', 'rb'))
validation_labels = np.array([0] * (val_first_class) + [1] * (val_second_class))



Создадим полносвязный слой и обучим его на полученных признаках
from keras.models import Sequential
from keras.callbacks import ModelCheckpoint
from keras.optimizers import SGD
from keras.layers import Dropout, Dense

model = Sequential()

model.add(Dense(512, activation='relu', input_shape=base_model.output_shape[1:]))
model.add(Dropout(0.5))
    
model.add(Dense(256, activation='relu', input_shape=base_model.output_shape[1:]))
model.add(Dropout(0.5))

model.add(Dense(128, activation='relu', input_shape=base_model.output_shape[1:]))
model.add(Dropout(0.5))    

model.add(Dense(64, activation='relu'))
model.add(Dropout(0.5))   

model.add(Dense(1, activation='sigmoid'))

model.compile(optimizer=SGD(lr=0.005),
              loss='binary_crossentropy',
              metrics=['accuracy'])

checkpointer = ModelCheckpoint(filepath='top-weights.hdf5', verbose=1, save_best_only=True)

history = model.fit(train_data,
                    train_labels,
                    epochs=epochs,
                    batch_size=batch_size,
                    callbacks=[checkpointer],
                    validation_data=(validation_data, validation_labels))
                    
                    
                    
                    
                    
Объединяем сверточные и полносвязные слои
from keras.models import Model

batch_size = 16
epochs = 50

input_tensor = Input(shape=(img_height,img_width,3))

base_model = SqueezeNet(weights='imagenet',
                          include_top=False,
                          input_shape=(img_width, img_height, 3),
                          pooling='avg')

top_model = Sequential()
    
top_model.add(Dense(512, activation='relu', input_shape=base_model.output_shape[1:]))
top_model.add(Dropout(0.5))

top_model.add(Dense(256, activation='relu', input_shape=base_model.output_shape[1:]))
top_model.add(Dropout(0.5))

top_model.add(Dense(128, activation='relu', input_shape=base_model.output_shape[1:]))
top_model.add(Dropout(0.5))  

top_model.add(Dense(64, activation='relu'))
top_model.add(Dropout(0.5))  

top_model.add(Dense(1, activation='sigmoid'))

top_model.load_weights('top-weights.hdf5')

model = Model(inputs=base_model.input, outputs=top_model(base_model.output))

model.compile(optimizer=SGD(lr=0.005, momentum=0.1, nesterov=True),
              loss='binary_crossentropy',
              metrics=['accuracy'])


checkpointer = ModelCheckpoint(filepath='weights.hdf5', verbose=1, save_best_only=True)

train_datagen = image.ImageDataGenerator(
        rescale=1./255,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True)

test_datagen = image.ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
        train_data_dir,
        target_size=(img_height, img_width),
        batch_size=batch_size,
        class_mode='binary')

validation_generator = test_datagen.flow_from_directory(
        validation_data_dir,
        target_size=(img_height, img_width),
        batch_size=batch_size,
        class_mode='binary')

history = model.fit_generator(train_generator,
                            steps_per_epoch=nb_train_samples // batch_size,
                            epochs=epochs,
                            validation_data=validation_generator,
                            validation_steps=nb_validation_samples // batch_size)
                            
                            
model.save('fake_orig_squeezenet_v1.h5')           
